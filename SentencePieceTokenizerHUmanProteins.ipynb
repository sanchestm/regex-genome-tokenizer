{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea78ae2-7e90-4fee-88e1-4792a81ff7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "#pip install -U tensorflow-text==2.6.0\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547b9932-4091-4112-be3c-647500fd3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.python.platform import gfile\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca64dbc-5b60-4fd3-b233-c29f06e7aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import requests\n",
    "import sentencepiece as spm\n",
    "from regexTokenizer import regexKmerTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56db4177-663b-4ba8-9676-f7471a0c4f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.6 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ID</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha-2-macroglobulin isoform a precursor</td>\n",
       "      <td>MGKNKLLHPSLVLLLLVLLPTDASVSGKPQYMVLVPSLLHTETTEK...</td>\n",
       "      <td>NP_000005.3</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arylamine N-acetyltransferase 2</td>\n",
       "      <td>MDIEAYFERIGYKNSRNKLDLETLTDILEHQIRAVPFENLNMHCGQ...</td>\n",
       "      <td>NP_000006.2</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium-chain specific acyl-CoA dehydrogenase,...</td>\n",
       "      <td>MAAGFGRCCRVLRSISRFHWRSQHTKANRQREPGLGFSFEFTEQQK...</td>\n",
       "      <td>NP_000007.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>short-chain specific acyl-CoA dehydrogenase, ...</td>\n",
       "      <td>MAAALLARASGPARRALCPRAWRQLHTIYQSVELPETHQMLLQTCR...</td>\n",
       "      <td>NP_000008.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very long-chain specific acyl-CoA dehydrogena...</td>\n",
       "      <td>MQAARMAASLGRQLLRLGGGSSRLTALLGQPRPGPARRPYAGGAAQ...</td>\n",
       "      <td>NP_000009.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115346</th>\n",
       "      <td>NADH dehydrogenase subunit 4L (mitochondrion)</td>\n",
       "      <td>MPLIYMNIMLAFTISLLGMLVYRSHLMSSLLCLEGMMLSLFIMATL...</td>\n",
       "      <td>YP_003024034.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115347</th>\n",
       "      <td>NADH dehydrogenase subunit 4 (mitochondrion)</td>\n",
       "      <td>MLKLIVPTIMLLPLTWLSKKHMIWINTTTHSLIISIIPLLFFNQIN...</td>\n",
       "      <td>YP_003024035.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115348</th>\n",
       "      <td>NADH dehydrogenase subunit 5 (mitochondrion)</td>\n",
       "      <td>MTMHTTMTTLTLTSLIPPILTTLVNPNKKNSYPHYVKSIVASTFII...</td>\n",
       "      <td>YP_003024036.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115349</th>\n",
       "      <td>NADH dehydrogenase subunit 6 (mitochondrion)</td>\n",
       "      <td>MMYALFLLSVGLVMGFVGFSSKPSPIYGGLVLIVSGVVGCVIILNF...</td>\n",
       "      <td>YP_003024037.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115350</th>\n",
       "      <td>cytochrome b (mitochondrion)</td>\n",
       "      <td>MTPMRKTNPLMKLINHSFIDLPTPSNISAWWNFGSLLGACLILQIT...</td>\n",
       "      <td>YP_003024038.1</td>\n",
       "      <td>[Homo sapiens]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115351 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0              alpha-2-macroglobulin isoform a precursor    \n",
       "1                        arylamine N-acetyltransferase 2    \n",
       "2        medium-chain specific acyl-CoA dehydrogenase,...   \n",
       "3        short-chain specific acyl-CoA dehydrogenase, ...   \n",
       "4        very long-chain specific acyl-CoA dehydrogena...   \n",
       "...                                                   ...   \n",
       "115346     NADH dehydrogenase subunit 4L (mitochondrion)    \n",
       "115347      NADH dehydrogenase subunit 4 (mitochondrion)    \n",
       "115348      NADH dehydrogenase subunit 5 (mitochondrion)    \n",
       "115349      NADH dehydrogenase subunit 6 (mitochondrion)    \n",
       "115350                      cytochrome b (mitochondrion)    \n",
       "\n",
       "                                                 sequence              ID  \\\n",
       "0       MGKNKLLHPSLVLLLLVLLPTDASVSGKPQYMVLVPSLLHTETTEK...     NP_000005.3   \n",
       "1       MDIEAYFERIGYKNSRNKLDLETLTDILEHQIRAVPFENLNMHCGQ...     NP_000006.2   \n",
       "2       MAAGFGRCCRVLRSISRFHWRSQHTKANRQREPGLGFSFEFTEQQK...     NP_000007.1   \n",
       "3       MAAALLARASGPARRALCPRAWRQLHTIYQSVELPETHQMLLQTCR...     NP_000008.1   \n",
       "4       MQAARMAASLGRQLLRLGGGSSRLTALLGQPRPGPARRPYAGGAAQ...     NP_000009.1   \n",
       "...                                                   ...             ...   \n",
       "115346  MPLIYMNIMLAFTISLLGMLVYRSHLMSSLLCLEGMMLSLFIMATL...  YP_003024034.1   \n",
       "115347  MLKLIVPTIMLLPLTWLSKKHMIWINTTTHSLIISIIPLLFFNQIN...  YP_003024035.1   \n",
       "115348  MTMHTTMTTLTLTSLIPPILTTLVNPNKKNSYPHYVKSIVASTFII...  YP_003024036.1   \n",
       "115349  MMYALFLLSVGLVMGFVGFSSKPSPIYGGLVLIVSGVVGCVIILNF...  YP_003024037.1   \n",
       "115350  MTPMRKTNPLMKLINHSFIDLPTPSNISAWWNFGSLLGACLILQIT...  YP_003024038.1   \n",
       "\n",
       "               species  \n",
       "0       [Homo sapiens]  \n",
       "1       [Homo sapiens]  \n",
       "2       [Homo sapiens]  \n",
       "3       [Homo sapiens]  \n",
       "4       [Homo sapiens]  \n",
       "...                ...  \n",
       "115346  [Homo sapiens]  \n",
       "115347  [Homo sapiens]  \n",
       "115348  [Homo sapiens]  \n",
       "115349  [Homo sapiens]  \n",
       "115350  [Homo sapiens]  \n",
       "\n",
       "[115351 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = regexKmerTokenizer(1000, overlapping= False, protein = True)\n",
    "%time df = tok.seq2pandas('human genome/GRCh38_latest_protein.faa.gz', docformat = 'fasta',from_file=True)\n",
    "def sppliter(name):\n",
    "    left, right = name.find(' '), name.rfind('[')\n",
    "    return [name[:left], name[left:right], name[right:]]\n",
    "df[['ID', 'name', 'species']] = [sppliter(i) for i in df.name]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b6ebc8-ba98-46bb-b9b4-fe11d123f48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    115351.000000\n",
       "mean        660.229049\n",
       "std         741.071372\n",
       "min          25.000000\n",
       "50%         489.000000\n",
       "90%        1264.000000\n",
       "90.5%      1292.000000\n",
       "91%        1322.000000\n",
       "91.5%      1359.000000\n",
       "92%        1400.000000\n",
       "92.5%      1437.000000\n",
       "93%        1478.000000\n",
       "93.5%      1521.000000\n",
       "94%        1575.000000\n",
       "94.5%      1630.000000\n",
       "95%        1693.000000\n",
       "95.5%      1761.000000\n",
       "96%        1839.000000\n",
       "96.5%      1922.000000\n",
       "97%        2039.000000\n",
       "97.5%      2181.250000\n",
       "98%        2353.000000\n",
       "98.5%      2567.000000\n",
       "99%        2977.000000\n",
       "99.5%      4220.500000\n",
       "100%      35991.000000\n",
       "max       35991.000000\n",
       "Name: sequence, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df.sequence.apply(len).describe(percentiles=list(np.linspace(0.9,1,21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2124a-d0e2-4667-9fd0-36ab0c92bebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1feb01-0ed6-4e9a-87cd-220e0866b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time spm.SentencePieceTrainer.train(sentence_iterator=iter(df.name), model_prefix='humanProtNames',\\\n",
    "                                     vocab_size=10000, hard_vocab_limit = False, max_sentencepiece_length =30, split_by_number = False, \n",
    "                                     split_by_unicode_script = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4f3135-06da-4bc8-bba2-52204a4670ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49min 20s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%time spm.SentencePieceTrainer.train(sentence_iterator=iter(df.sequence), model_prefix='humanProtAA', \\\n",
    "                                     vocab_size=30000,  max_sentence_length = 36000, max_sentencepiece_length =30, \\\n",
    "                                     hard_vocab_limit = False, train_extremely_large_corpus= True,\\\n",
    "                                     pad_id =-1, bos_piece = 'bos',  eos_piece = 'eos') #bos_id = -1, eos_id = -1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d2c4d-92e9-401f-90dc-3196894a1f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180df38c-eb84-401c-8304-afc288d538aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15453757-ddbb-47f0-ba4f-6a57b26901e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2553fb4-86f4-4a2f-878a-608bbe4058a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='humanProtNames.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f65c4ac-bc05-48b6-b627-3d201ed71f5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SentencePieceProcessor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNADH 3.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'SentencePieceProcessor' object is not callable"
     ]
    }
   ],
   "source": [
    "sp('NADH 3.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69003b6c-7a98-465e-bb00-7795ee5d6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.encode_as_ids('NADH 3.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa39271-3b12-4c70-9773-0ef20662de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = sp.Encode(df.sequence.iloc[3][10:1000])\n",
    "print(encoded_input)\n",
    "\n",
    "tokenized_input = [sp.IdToPiece(id) for id in encoded_input]\n",
    "print(*tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b10bc-7811-4fcb-9d77-a7ba1c488197",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gfile.GFile('humanProtNames.model', 'rb').read()\n",
    "SPT = tf_text.SentencepieceTokenizer(model=model, out_type=tf.string, nbest_size=0, alpha=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81842cd-74eb-49ab-96b2-beb927545a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sequence.iloc[3][10:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d76bdd-ecdf-4437-b106-c1667dc23f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPT.tokenize('NADH ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc8f74-304b-4b48-b9a5-657edf4aa560",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPT.detokenize(SPT.tokenize(df.sequence.iloc[3][10:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841bd937-3b81-40e8-8d33-d3a2fa24c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "%time biglist = list(chain.from_iterable(tok(df.sequence[:100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079234e-2b7d-4b81-8442-929c0f590105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60744889-cb54-4cea-b06b-0b1077ccac24",
   "metadata": {},
   "source": [
    "--help (show help)  type: bool default: false\n",
    "--version (show version)  type: bool default: false\n",
    "--minloglevel (Messages logged at a lower level than this don't actually get logged anywhere)  type: int default: 0\n",
    "--input (comma separated list of input sentences)  type: std::string default: \"\"\n",
    "--input_format (Input format. Supported format is `text` or `tsv`.)  type: std::string default: \"\"\n",
    "--model_prefix (output model prefix)  type: std::string default: \"\"\n",
    "--model_type (model algorithm: unigram, bpe, word or char)  type: std::string default: \"unigram\"\n",
    "--vocab_size (vocabulary size)  type: int32 default: 8000\n",
    "--accept_language (comma-separated list of languages this model can accept)  type: std::string default: \"\"\n",
    "--self_test_sample_size (the size of self test samples)  type: int32 default: 0\n",
    "--character_coverage (character coverage to determine the minimum symbols)  type: double default: 0.9995\n",
    "--input_sentence_size (maximum size of sentences the trainer loads)  type: int32 default: 0\n",
    "--shuffle_input_sentence (Randomly sample input sentences in advance. Valid when --input_sentence_size > 0)  type: bool default: true\n",
    "--seed_sentencepiece_size (the size of seed sentencepieces)  type: int32 default: 1000000\n",
    "--shrinking_factor (Keeps top shrinking_factor pieces with respect to the loss)  type: double default: 0.75\n",
    "--num_threads (number of threads for training)  type: int32 default: 16\n",
    "--num_sub_iterations (number of EM sub-iterations)  type: int32 default: 2\n",
    "--max_sentencepiece_length (maximum length of sentence piece)  type: int32 default: 16\n",
    "--max_sentence_length (maximum length of sentence in byte)  type: int32 default: 4192\n",
    "--split_by_unicode_script (use Unicode script to split sentence pieces)  type: bool default: true\n",
    "--split_by_number (split tokens by numbers (0-9))  type: bool default: true\n",
    "--split_by_whitespace (use a white space to split sentence pieces)  type: bool default: true\n",
    "--split_digits (split all digits (0-9) into separate pieces)  type: bool default: false\n",
    "--treat_whitespace_as_suffix (treat whitespace marker as suffix instead of prefix.)  type: bool default: false\n",
    "--control_symbols (comma separated list of control symbols)  type: std::string default: \"\"\n",
    "--user_defined_symbols (comma separated list of user defined symbols)  type: std::string default: \"\"\n",
    "--required_chars (UTF8 characters in this flag are always used in the character set regardless of --character_coverage)  type: std::string default: \"\"\n",
    "--byte_fallback (decompose unknown pieces into UTF-8 byte pieces)  type: bool default: false\n",
    "--vocabulary_output_piece_score (Define score in vocab file)  type: bool default: true\n",
    "--normalization_rule_name (Normalization rule name. Choose from nfkc or identity)  type: std::string default: \"nmt_nfkc\"\n",
    "--normalization_rule_tsv (Normalization rule TSV file. )  type: std::string default: \"\"\n",
    "--denormalization_rule_tsv (Denormalization rule TSV file.)  type: std::string default: \"\"\n",
    "--add_dummy_prefix (Add dummy whitespace at the beginning of text)  type: bool default: true\n",
    "--remove_extra_whitespaces (Removes leading, trailing, and duplicate internal whitespace)  type: bool default: true\n",
    "--hard_vocab_limit (If set to false, --vocab_size is considered as a soft limit.)  type: bool default: true\n",
    "--use_all_vocab (If set to true, use all tokens as vocab. Valid for word/char models.)  type: bool default: false\n",
    "--unk_id (Override UNK (<unk>) id.)  type: int32 default: 0\n",
    "--bos_id (Override BOS (<s>) id. Set -1 to disable BOS.)  type: int32 default: 1\n",
    "--eos_id (Override EOS (</s>) id. Set -1 to disable EOS.)  type: int32 default: 2\n",
    "--pad_id (Override PAD (<pad>) id. Set -1 to disable PAD.)  type: int32 default: -1\n",
    "--unk_piece (Override UNK (<unk>) piece.)  type: std::string default: \"<unk>\"\n",
    "--bos_piece (Override BOS (<s>) piece.)  type: std::string default: \"<s>\"\n",
    "--eos_piece (Override EOS (</s>) piece.)  type: std::string default: \"</s>\"\n",
    "--pad_piece (Override PAD (<pad>) piece.)  type: std::string default: \"<pad>\"\n",
    "--unk_surface (Dummy surface string for <unk>. In decoding <unk> is decoded to `unk_surface`.)  type: std::string default: \" ⁇ \"\n",
    "--train_extremely_large_corpus (Increase bit depth for unigram tokenization.)  type: bool default: false"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2gpu]",
   "language": "python",
   "name": "conda-env-tf2gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
